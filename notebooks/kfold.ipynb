{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT_DIR = Path.cwd().parents[0]\n",
    "sys.path.append(str(ROOT_DIR))\n",
    "\n",
    "from src.preprocessing import processing_data\n",
    "\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(\"../data/raw/train.csv\", index_col='id')\n",
    "X_test = pd.read_csv(\"../data/raw/test.csv\", index_col='id')\n",
    "\n",
    "#Further analysis of data\n",
    "y = train_data[\"exam_score\"]\n",
    "X = train_data.drop(columns=\"exam_score\")\n",
    "\n",
    "#categorical columns\n",
    "cat_col = [col for col in X.columns if(X[col].dtype == 'object')]\n",
    "\n",
    "#numerical columns\n",
    "num_col = [col for col in X.columns if(X[col].dtype == 'int64' or X[col].dtype == 'float64')]\n",
    "\n",
    "ordinal_col = [\"internet_access\",\"facility_rating\",\"exam_difficulty\"]\n",
    "nominal_col = [\"gender\", \"course\",\"sleep_quality\",\"study_method\"]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2,random_state=1)\n",
    "\n",
    "preprocess_trf = processing_data(num_col, ordinal_col, nominal_col)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02c26c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF Ridge RMSE: 8.894825663262274\n"
     ]
    }
   ],
   "source": [
    "#Training the Ridge model using KFold method\n",
    "\n",
    "oof_ridge = np.zeros(len(X))\n",
    "test_ridge = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "    y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "    ridge = Ridge(alpha=0.05, random_state=42)\n",
    "\n",
    "    ridge_pipe = Pipeline([\n",
    "        (\"preprocess\", preprocess_trf),\n",
    "        (\"model\", ridge)\n",
    "    ])\n",
    "\n",
    "    ridge_pipe.fit(X_tr, y_tr)\n",
    "\n",
    "    oof_ridge[val_idx] = ridge_pipe.predict(X_val)\n",
    "    test_ridge += ridge_pipe.predict(X_test) / kf.n_splits\n",
    "\n",
    "print(\"OOF Ridge RMSE:\",\n",
    "      root_mean_squared_error(y, oof_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7829ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF HGB RMSE: 8.760338247300833\n"
     ]
    }
   ],
   "source": [
    "#Training the HGB model using KFold method\n",
    "\n",
    "oof_hgb = np.zeros(len(X))\n",
    "test_hgb = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "    y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "    hgb = HistGradientBoostingRegressor(\n",
    "        learning_rate=0.03,\n",
    "        max_iter=1200,\n",
    "        max_leaf_nodes=64,\n",
    "        max_depth=6,\n",
    "        min_samples_leaf=20,\n",
    "        max_features=0.7,\n",
    "        l2_regularization=0.3,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        n_iter_no_change=50,\n",
    "        random_state=7\n",
    "    )\n",
    "\n",
    "    hgb_pipe = Pipeline([\n",
    "        (\"preprocess\", preprocess_trf),\n",
    "        (\"model\", hgb)\n",
    "    ])\n",
    "\n",
    "    hgb_pipe.fit(X_tr, y_tr)\n",
    "\n",
    "    oof_hgb[val_idx] = hgb_pipe.predict(X_val)\n",
    "    test_hgb += hgb_pipe.predict(X_test) / kf.n_splits\n",
    "\n",
    "print(\"OOF HGB RMSE:\",\n",
    "      root_mean_squared_error(y, oof_hgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b899ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge weight 0.10 → OOF RMSE 8.76262\n",
      "Ridge weight 0.20 → OOF RMSE 8.76656\n",
      "Ridge weight 0.25 → OOF RMSE 8.76955\n",
      "Ridge weight 0.30 → OOF RMSE 8.77321\n",
      "Ridge weight 0.35 → OOF RMSE 8.77755\n"
     ]
    }
   ],
   "source": [
    "#Testing weighted combined values of the 2 models\n",
    "for w in [0.1, 0.2, 0.25, 0.3, 0.35]:\n",
    "    oof_ens = w * oof_ridge + (1 - w) * oof_hgb\n",
    "    rmse = root_mean_squared_error(y, oof_ens)\n",
    "    print(f\"Ridge weight {w:.2f} → OOF RMSE {rmse:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247f5d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../data/raw/sample_submission.csv\")\n",
    "final_test_pred = test_hgb\n",
    "submission = sample_submission.copy()\n",
    "submission[\"exam_score\"] = final_test_pred\n",
    "submission.to_csv(\n",
    "    \"../sumissions/submission_oof_hgb.csv\",\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
